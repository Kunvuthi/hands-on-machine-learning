{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fetching the MNIST Dataset \n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 'data' is an array of data with 1 row per instance and one column per feature\n",
    "### 'target' is the label\n",
    "\n",
    "x, y = mnist['data'], mnist['target']\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  38.,  43., 105.,\n",
       "       255., 253., 253., 253., 253., 253., 174.,   6.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  43., 139., 224., 226., 252., 253., 252., 252., 252., 252.,\n",
       "       252., 252., 158.,  14.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 178., 252., 252., 252.,\n",
       "       252., 253., 252., 252., 252., 252., 252., 252., 252.,  59.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 109., 252., 252., 230., 132., 133., 132., 132., 189.,\n",
       "       252., 252., 252., 252.,  59.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,  29.,  29.,\n",
       "        24.,   0.,   0.,   0.,   0.,  14., 226., 252., 252., 172.,   7.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        85., 243., 252., 252., 144.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  88., 189., 252., 252., 252.,  14.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  91., 212.,\n",
       "       247., 252., 252., 252., 204.,   9.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  32.,\n",
       "       125., 193., 193., 193., 253., 252., 252., 252., 238., 102.,  28.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  45., 222., 252., 252., 252., 252., 253.,\n",
       "       252., 252., 252., 177.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  45.,\n",
       "       223., 253., 253., 253., 253., 255., 253., 253., 253., 253.,  74.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  31., 123.,  52.,  44.,  44.,\n",
       "        44.,  44., 143., 252., 252.,  74.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  15., 252., 252.,\n",
       "        74.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  86., 252., 252.,  74.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,\n",
       "        75.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,  98., 242., 252.,\n",
       "       252.,  74.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  61., 183., 252.,  29.,   0.,   0.,   0.,\n",
       "         0.,  18.,  92., 239., 252., 252., 243.,  65.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 208.,\n",
       "       252., 252., 147., 134., 134., 134., 134., 203., 253., 252., 252.,\n",
       "       188.,  83.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 208., 252., 252., 252., 252., 252.,\n",
       "       252., 252., 252., 253., 230., 153.,   8.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        49., 157., 252., 252., 252., 252., 252., 217., 207., 146.,  45.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   7., 103., 235., 252.,\n",
       "       172., 103.,  24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### There are 70,000 images of digits and each image has 784 features as it is a 28 x 28 pixels image.\n",
    "### Whereas each number determines one pixel intensity of black. (white 0 to black 255).\n",
    "\n",
    "some_number = x[7]\n",
    "some_number\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some_number_image = some_number.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_number_image, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Indeed it is a 2. But note the arrays of y are stored as a string. So lets convert it to an int.\n",
    "\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The MNIST dataset has already split into training and testing set for us, which it is already shuffled and the first 60,000\n",
    "### instances should be used as a training set and the rest as a testing set. \n",
    "\n",
    "x_train, x_test, y_train, y_test = x[:60000],x[60000:],y[:60000],y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With this we can train a model to identify whether it is that certain digit or not. For instance, whether it is a 3 or not.\n",
    "### It then returns a true or false boolean.\n",
    "\n",
    "y_train_3 = (y_train == 3)\n",
    "y_test_3 = (y_test == 3) \n",
    "\n",
    "### This returns an array of True for all 3s, False for all other digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Stochastic Gradient Descent (SGD) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=47)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note: SGD is similar to GD. It computes gradients, intercepts and a regression however can be used as a classifier as well, as most regression do.\n",
    "## SGD is more computationally efficient than gradient descent when you have much larger datasets. SGD is also really good when\n",
    "## you have a lot of attributes or parameters.\n",
    "## for more information, watch a YouTube video: https://www.youtube.com/watch?v=vMh0zPT0tLI\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=47)\n",
    "sgd_clf.fit(x_train, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([x[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Measuring Accuracy using Cross-Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96775, 0.95135, 0.95795])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, x_train, y_train_3, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8962 , 0.89975, 0.8975 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### To show that whether this performance measure is credible or not, we can map all of the x_train label as false or 0. Then \n",
    "## see how accurate it would get. If it is a high percentage, then that means the labels of 'true' is much much less than the\n",
    "## labels of 'false'. Essentially, you have a high percentage of getting the answer right although, you are justing saying all of them\n",
    "## are false.\n",
    "\n",
    "from sklearn.base import BaseEstimator  \n",
    "\n",
    "class AlwaysNever3Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),1), dtype=bool)\n",
    "    \n",
    "never_3_clf = AlwaysNever3Classifier()\n",
    "cross_val_score(never_3_clf, x_train, y_train_3, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### So essentially 89% to 90% of this whole data are non-3s. So measuing accuracy is generally not the preferred performance\n",
    "### measure for classifiers, especially when dealing with skewed datasets (ie: when some classes are much more frequent than othes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Before computing the confusion matrix, we need a set of predictions so it can be compared with the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict \n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, x_train, y_train_3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The cross_val_predict() method performs K-fold cross-validation, but instead of returning the evaluation scores, it returns prediction\n",
    "### made on each test fold. This means that you can get a clean prediction for each instance in the training set.\n",
    "### Note: Clean = prediction made by the model that never saw the data during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52427,  1442],\n",
       "       [ 1017,  5114]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train_3, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To understand what is being displayed, check 'Confusion-matrix-for-binary-classification' in the media and notes folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We have 2 measures: Precision & Recall.\n",
    "### Check in the media and notes folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7800488102501525"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train_3, y_train_pred) # == 5114 / (1442 + 5114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8341216767248409"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_3, y_train_pred) # == 5114 / (1017 + 5114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## - Precision is the score representing out of all the time when the model claims the digit as 3, 78% of it is correct. \n",
    "## - Recall is the score representing out all the 3s, it detects 83% of them.\n",
    "## - F1 score is a score combining both measures above. Formula is in the M&N folder. It is a harmonic mean. Rather than treating\n",
    "## the values equally, it gives much more weight to low values. So it can only have a bigger value when BOTH measures is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061795538740444"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_3, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## - F1 score favors classifiers that have similar precision and recall. This is not always the case: sometimes you would care\n",
    "## more about the precision and sometimes more about the recall. \n",
    "\n",
    "## - Eg.1: You would prefer a higher precision model if you are using the model for detecting safe videos for kids. \n",
    "\n",
    "## - Eg.2: You would prefer a higher recall model if you are using to detect shop-lifting (sure they can get more false-alarm but\n",
    "##         But it is better than missing an actual shop-lifting activity.)\n",
    "\n",
    "## You can't have both at high. This is called the precision/recall trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5014.18518579])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores = sgd_clf.decision_function([some_number])\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the decision funtion returns a score for each instance, then use it to compare with the threshold to predict whether positive\n",
    "## or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## if the threshold is at 0, then the prediction would say the some_number is a 3. (which is true)\n",
    "\n",
    "threshold = 0\n",
    "y_some_number_pred = (y_scores > threshold)\n",
    "y_some_number_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## if we increase the threshold to 8000, then the prediction would say some_number isn't a 3. \n",
    "\n",
    "threshold = 8000\n",
    "y_some_number_pred = (y_scores > threshold)\n",
    "y_some_number_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This show us that when we increase the threshold, the recall score decreases (ie: higher false negative rate).\n",
    "\n",
    "## So how do we know which threshold to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first use cross_val_predict\n",
    "\n",
    "y_scores = cross_val_predict(sgd_clf, x_train, y_train_3, cv=3, method='decision_function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_3, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"r-\", label=\"Recalls\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.grid()\n",
    "    \n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
